{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# CNN"
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "소스 원 위치 : https://github.com/golbin/TensorFlow-Tutorials/blob/master/07%20-%20CNN/02%20-%20tf.layers.py\n\n변경 사항\n- mnist = input_data.read_data_sets(\"../mnist/data/\", one_hot=True)"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 신경망 구성을 손쉽게 해 주는 유틸리티 모음인 tensorflow.layers 를 사용해봅니다.\n# 01 - CNN.py 를 재구성한 것이니, 소스를 한 번 비교해보세요.\n# 이처럼 TensorFlow 에는 간단하게 사용할 수 있는 다양한 함수와 유틸리티들이 매우 많이 마련되어 있습니다.\n# 다만, 처음에는 기본적인 개념에 익숙히지는 것이 좋으므로 이후에도 가급적 기본 함수들을 이용하도록 하겠습니다.\nimport tensorflow as tf\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"../mnist/data/\", one_hot=True)\n\n#########\n# 신경망 모델 구성\n######\nX = tf.placeholder(tf.float32, [None, 28, 28, 1])\nY = tf.placeholder(tf.float32, [None, 10])\nis_training = tf.placeholder(tf.bool)\n\n# 기본적으로 inputs, outputs size, kernel_size 만 넣어주면\n# 활성화 함수 적용은 물론, 컨볼루션 신경망을 만들기 위한 나머지 수치들은 알아서 계산해줍니다.\n# 특히 Weights 를 계산하는데 xavier_initializer 를 쓰고 있는 등,\n# 크게 신경쓰지 않아도 일반적으로 효율적인 신경망을 만들어줍니다.\nL1 = tf.layers.conv2d(X, 32, [3, 3])\nL1 = tf.layers.max_pooling2d(L1, [2, 2], [2, 2])\nL1 = tf.layers.dropout(L1, 0.7, is_training)\n\nL2 = tf.layers.conv2d(L1, 64, [3, 3])\nL2 = tf.layers.max_pooling2d(L2, [2, 2], [2, 2])\nL2 = tf.layers.dropout(L2, 0.7, is_training)\n\nL3 = tf.contrib.layers.flatten(L2)\nL3 = tf.layers.dense(L3, 256, activation=tf.nn.relu)\nL3 = tf.layers.dropout(L3, 0.5, is_training)\n\nmodel = tf.layers.dense(L3, 10, activation=None)\n\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\noptimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n\n#########\n# 신경망 모델 학습\n######\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\n\nbatch_size = 100\ntotal_batch = int(mnist.train.num_examples/batch_size)\n\nfor epoch in range(15):\n    total_cost = 0\n\n    for i in range(total_batch):\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n        _, cost_val = sess.run([optimizer, cost],\n                               feed_dict={X: batch_xs,\n                                          Y: batch_ys,\n                                          is_training: True})\n        total_cost += cost_val\n\n    print('Epoch:', '%04d' % (epoch + 1),\n          'Avg. cost =', '{:.4f}'.format(total_cost / total_batch))\n\nprint('최적화 완료!')\n\n#########\n# 결과 확인\n######\nis_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\nprint('정확도:', sess.run(accuracy,\n                        feed_dict={X: mnist.test.images.reshape(-1, 28, 28, 1),\n                                   Y: mnist.test.labels,\n                                   is_training: False}))",
      "execution_count": 1,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n  return f(*args, **kwds)\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Extracting ../mnist/data/train-images-idx3-ubyte.gz\nExtracting ../mnist/data/train-labels-idx1-ubyte.gz\nExtracting ../mnist/data/t10k-images-idx3-ubyte.gz\nExtracting ../mnist/data/t10k-labels-idx1-ubyte.gz\nEpoch: 0001 Avg. cost = 0.1693\nEpoch: 0002 Avg. cost = 0.0484\nEpoch: 0003 Avg. cost = 0.0308\nEpoch: 0004 Avg. cost = 0.0206\nEpoch: 0005 Avg. cost = 0.0151\nEpoch: 0006 Avg. cost = 0.0133\nEpoch: 0007 Avg. cost = 0.0126\nEpoch: 0008 Avg. cost = 0.0101\nEpoch: 0009 Avg. cost = 0.0072\nEpoch: 0010 Avg. cost = 0.0064\nEpoch: 0011 Avg. cost = 0.0061\nEpoch: 0012 Avg. cost = 0.0069\nEpoch: 0013 Avg. cost = 0.0062\nEpoch: 0014 Avg. cost = 0.0059\nEpoch: 0015 Avg. cost = 0.0031\n최적화 완료!\n정확도: 0.9903\n"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}