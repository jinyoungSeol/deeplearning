{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# IRIS"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "코드 원 위치 : https://www.tensorflow.org/get_started/tflearn\n\n라인 6, 22, 27의 urllib를 urllib.request로 수정.\n라인 13, 16의 csv파일 위치를 ../ 로 변경. Azure notebook에서 업로드 하면 ../로 올라간다.\n\n다음 2개의 파일을 다운로드하고 메뉴 Data > Upload... 를 사용하여 업로드한다.\n- http://download.tensorflow.org/data/iris_training.csv\n- http://download.tensorflow.org/data/iris_test.csv"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport urllib.request\n\nimport numpy as np\nimport tensorflow as tf\n\n\n# Data sets\nIRIS_TRAINING = \"./iris_training.csv\"\nIRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n\nIRIS_TEST = \"./iris_test.csv\"\nIRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n\ndef main():\n  # If the training and test sets aren't stored locally, download them.\n  if not os.path.exists(IRIS_TRAINING):\n    raw = urllib.request.urlopen(IRIS_TRAINING_URL).read()\n    with open(IRIS_TRAINING, \"w\") as f:\n      f.write(raw)\n\n  if not os.path.exists(IRIS_TEST):\n    raw = urllib.request.urlopen(IRIS_TEST_URL).read()\n    with open(IRIS_TEST, \"w\") as f:\n      f.write(raw)\n\n  # Load datasets.\n  training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n      filename=IRIS_TRAINING,\n      target_dtype=np.int,\n      features_dtype=np.float32)\n  test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n      filename=IRIS_TEST,\n      target_dtype=np.int,\n      features_dtype=np.float32)\n\n  # Specify that all features have real-value data\n  feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n\n  # Build 3 layer DNN with 10, 20, 10 units respectively.\n  classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n                                              hidden_units=[10, 20, 10],\n                                              n_classes=3,\n                                              model_dir=\"iris_model\")\n  # Define the training inputs\n  def get_train_inputs():\n    x = tf.constant(training_set.data)\n    y = tf.constant(training_set.target)\n\n    return x, y\n\n  # Fit model.\n  classifier.fit(input_fn=get_train_inputs, steps=2000)\n\n  # Define the test inputs\n  def get_test_inputs():\n    x = tf.constant(test_set.data)\n    y = tf.constant(test_set.target)\n\n    return x, y\n\n  # Evaluate accuracy.\n  accuracy_score = classifier.evaluate(input_fn=get_test_inputs,\n                                       steps=1)[\"accuracy\"]\n\n  print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n\n  # Classify two new flower samples.\n  def new_samples():\n    return np.array(\n      [[6.4, 3.2, 4.5, 1.5],\n       [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)\n\n  predictions = list(classifier.predict(input_fn=new_samples))\n\n  print(\n      \"New Samples, Class Predictions:    {}\\n\"\n      .format(predictions))\n\nif __name__ == \"__main__\":\n    main()",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow._api.v2.compat' has no attribute 'learn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e7cf8f8f9c5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-e7cf8f8f9c5d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m# Load datasets.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   training_set = tf.compat.learn.datasets.base.load_csv_with_header(\n\u001b[0m\u001b[1;32m     33\u001b[0m       \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIRIS_TRAINING\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mtarget_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.compat' has no attribute 'learn'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}